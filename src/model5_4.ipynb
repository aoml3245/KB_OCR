{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aloml2543/KB_OCR/blob/main/src/model5_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CbPHIIjMoA7"
      },
      "outputs": [],
      "source": [
        "# %cp /content/drive/MyDrive/KB_OCR/DATA/data.yaml /content/\n",
        "%cp /content/drive/MyDrive/KB_OCR/DATA/mk_img.zip /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zsz5URG_ACZ9"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\"\"\"\n",
        "출처\n",
        "https://codesample-factory.tistory.com/1343 > 이미지 노이즈 처리\n",
        "https://www.youtube.com/watch?v=T0DO1C8uYP8 > 빵형의 개발도상국\n",
        "https://www.mcst.go.kr/kor/s_policy/subPolicy/contents/contents09.jsp > 안심 글꼴\n",
        "\n",
        "이미지 검색\n",
        "> https://unsplash.com/s/photos/pixel\n",
        "> https://pixabay.com/\n",
        "\n",
        "이미지 출처\n",
        "><a href=\"https://pixabay.com/ko/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2658014\">Pixabay</a>로부터 입수된 <a href=\"https://pixabay.com/ko/users/davidzydd-985081/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2658014\">David Zydd</a>님의 이미지 입니다.\n",
        "\"\"\"\n",
        "!pip install jamo\n",
        "!pip install hangul_utils\n",
        "!pip install parmap\n",
        "!pip install wget\n",
        "import warnings\n",
        "import wget\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import parmap\n",
        "import yaml\n",
        "import multiprocessing\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "from jamo import j2hcj, h2j\n",
        "from sklearn.cluster import KMeans \n",
        "from PIL import ImageFont, ImageDraw, Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "from hangul_utils import split_syllables,join_jamos\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xerj7MPaW77l"
      },
      "outputs": [],
      "source": [
        "dir_ = os.getcwd() + '/dataset/Font/'\n",
        "URL = \"https://onedrive.live.com/download?cid=44F5C59EE841EE0A&resid=44F5C59EE841EE0A%21244402&authkey=ABfBdDi5elNBoss\"\n",
        "\n",
        "if not(os.path.isdir(dir_)):\n",
        "  os.makedirs(os.path.join(dir_))\n",
        "\n",
        "file_ = os.getcwd() + '/dataset/Font.zip'\n",
        "wget.download(URL, file_)\n",
        "\n",
        "dir_ = os.getcwd() + '/dataset/Font'\n",
        "!unzip -n '{file_}'  -d '{dir_}'\n",
        "\n",
        "try:\n",
        "  os.remove(dir_ + '/- (146).ttf')\n",
        "  os.remove(dir_ + '/- (148).ttf')\n",
        "  os.remove(dir_ + '/- (149).ttf')\n",
        "except:\n",
        "  pass\n",
        "\n",
        "file_ = os.getcwd() + '/dataset/data.yaml'\n",
        "URL=\"https://onedrive.live.com/download?cid=44F5C59EE841EE0A&resid=44F5C59EE841EE0A%21244403&authkey=ACcKIYIEAbe10lY\"\n",
        "wget.download(URL, file_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWrHImwgA4V_"
      },
      "outputs": [],
      "source": [
        "class hangle_img():\n",
        "  def __init__(self):\n",
        "    self.img_loc = os.getcwd() + '/dataset/images/'\n",
        "    self.label_loc = os.getcwd() + '/dataset/labels/'\n",
        "    self.font_dir = os.getcwd() + '/dataset/Font/'\n",
        "    \n",
        "    if not(os.path.isdir(self.img_loc)):\n",
        "      os.makedirs(os.path.join(self.img_loc))\n",
        "    if not(os.path.isdir(self.label_loc)):\n",
        "      os.makedirs(os.path.join(self.label_loc))\n",
        "    \n",
        "    self.font_list = os.listdir(self.font_dir)\n",
        "    if '.ipynb_checkpoints' in self.font_list:\n",
        "      font_list.remove('.ipynb_checkpoints')\n",
        "\n",
        "    self.info = {\n",
        "        'char_dic': {'ㄱ': 144,'ㄲ': 145,'ㄴ': 146,'ㄷ': 147,'ㄹ': 148,'ㅁ': 149,'ㅂ': 150,'ㅅ': 151,'ㅆ': 152,'ㅇ': 153,'ㅈ': 154,'ㅊ': 155,'ㅋ': 156,'ㅌ': 157,'ㅍ': 158,'ㅎ': 159},\n",
        "        '0' : ''' ㄱㄲㄴㄷㄸㄹㅁㅂㅃㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎㅏㅐㅑㅒㅓㅔㅕㅖㅗㅘㅙㅚㅛㅜㅝㅞㅟㅠㅡㅢㅣabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.,/?'\";:][}{)(<>+=-_*&^%$#@!~\\\\ㄳㄵㄶㄺㄻㄼㄽㄾㄿㅀㅄ''',\n",
        "        'w_0' : [10,2,10,2,4,6,10,10,2,10,2,10,10,2,10,4,4,4,4,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "        '1' : \"\"\" ㅏㅐㅑㅒㅓㅔㅕㅖㅗㅘㅙㅚㅛㅜㅝㅞㅟㅠㅡㅢㅣ\"\"\",\n",
        "        'w_1' : [5,5,3,3,2,5,3,2,1,5,3,2,2,3,5,3,1,1,3,4,1,3,],\n",
        "        '2' : \"\"\" ㄱㄲㄳㄴㄵㄶㄷㄹㄺㄻㄼㄽㄾㄿㅀㅁㅂㅄㅅㅆㅇㅈㅊㅋㅌㅍㅎ\"\"\",\n",
        "        'w_2' : [10,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
        "        'only_0' : \"\"\"ㄳㄵㄶㄺㄻㄼㄽㄾㄿㅀㅄㅏㅐㅑㅒㅓㅔㅕㅖㅗㅘㅙㅚㅛㅜㅝㅞㅟㅠㅡㅢㅣabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.,/?'\";:][}{)(<>+=-_*&^%$#@!~\\\\\"\"\",\n",
        "        'not_kor' : ''' abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.,/?'\";:][}{)(<>+=-_*&^%$#@!~\\\\''',\n",
        "        'ans_cha' : ''' ㄱㄲㄴㄷㄸㄹㅁㅂㅃㅅㅆㅇㅈㅉㅊㅋㅌㅍㅎㅏㅐㅑㅒㅓㅔㅕㅖㅗㅘㅙㅚㅛㅜㅝㅞㅟㅠㅡㅢㅣabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.,/?'\";:][}{)(<>+=-_*&^%$#@!~\\\\ㄳㄵㄶㄺㄻㄼㄽㄾㄿㅀㅄ''',\n",
        "        'char_dic' : {144: 'ㄱ',145: 'ㄲ',146: 'ㄴ',147: 'ㄷ',148: 'ㄹ',149: 'ㅁ',150: 'ㅂ',151: 'ㅅ',152: 'ㅆ',153: 'ㅇ',154: 'ㅈ',155: 'ㅊ',156: 'ㅋ',157: 'ㅌ',158: 'ㅍ',159: 'ㅎ'},\n",
        "        'name' : ['space','giuk','Xgiuk','nien','diged','Xdiged','lier', 'miem', 'biep', 'Xbiep', 'siot', 'Xsiot', 'ieng', 'jied', 'Xjied', 'chied', 'kieck', 'tiet', 'piep', 'hied', 'AH', 'AEH-I', 'YAH', 'YAEH-I', 'EOH', 'AEH-O', 'YEOH', 'YAEH-O', 'OH', 'OH-AH' ,'OH-AEH-I', 'OH-EE', 'YOH', 'OO', 'OO-EOH', 'OO-AEH-O', 'OO-EE', 'YOO', 'EH', 'EH-EE' ,'EE', 'a' ,'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9','.', ',', '/', '?', \"'\",'\"', ';',':',']','[','}','{',')','(','<', '>', '+', '=', '-', '_', '*', '&', '^', '%', '$', '#', '@', '!', '~', '\\\\', '_gisi', '_niji', '_nihi', '_ligi', '_limi', '_libi', '_lisi', '_liti' ,'_lipi', '_lihi', '_bisi', '_giuk', '_Xgiuk', '_nien', '_diged', '_lier', '_miem', '_biep', '_siot', '_Xsiot', '_ieng', '_jied', '_chied', '_kieck', '_tiet', '_piep', '_hied', 'letter']\n",
        "    }\n",
        "    \n",
        "\n",
        "  def ri(self, x, y):\n",
        "    return random.randint(x,y)\n",
        "\n",
        "  def _get_data(self, data=None):\n",
        "    word = ''\n",
        "    if data == None:\n",
        "      length = self.ri(1, 20)\n",
        "      for n in range(length):\n",
        "        letter_ = ''\n",
        "        for jong in range(3):\n",
        "          letter_ += random.choices(self.info[str(jong)], weights=self.info[\"w_\"+str(jong)])[0]\n",
        "          if letter_[jong] == \" \" :\n",
        "            break\n",
        "          if jong == 0:\n",
        "            if letter_[jong] in self.info['only_0']:\n",
        "              break\n",
        "        word += join_jamos(letter_)\n",
        "    else:\n",
        "      length = len(data)\n",
        "      word = data\n",
        "    \n",
        "    while True:\n",
        "      if word == '':\n",
        "        break\n",
        "      if word[0] == ' ':\n",
        "        word = word[1:]\n",
        "      else:\n",
        "        break\n",
        "    length = len(word)\n",
        "    while True:\n",
        "      if word == '':\n",
        "        break\n",
        "      if word[length-1] == ' ':\n",
        "        word = word[:length-1]\n",
        "        length = len(word)\n",
        "      else:\n",
        "        break\n",
        "\n",
        "    for i in reversed(range(1, len(word)-2)):\n",
        "      \n",
        "      if word[i] == ' ':\n",
        "        if word[i-1] == ' ':\n",
        "          word = word[:i]+word[i+1:]\n",
        "          length = len(word)\n",
        "    \n",
        "    if word == '':\n",
        "      raise Exception('\\nword를 만들던 중 길이가 0인 데이터가 발생했습니다. 다음인덱스로 넘어갑니다.')\n",
        "  \n",
        "    letter_size = 50\n",
        "    \n",
        "    word_width = length * letter_size + 30 #margin for font's irregular position\n",
        "    back_img_size = (word_width+self.ri(1, 20),word_width+self.ri(1, 20),3) #height, width, channel\n",
        "\n",
        "    r_font = random.choices(self.font_list)[0]\n",
        "    font = ImageFont.truetype(self.font_dir + r_font, size=letter_size)\n",
        "    w_li_ = []\n",
        "    for word_ in ['가', '가 가','가가']:\n",
        "\n",
        "      img_ = np.zeros(back_img_size, dtype=np.uint8)\n",
        "      img_ = Image.fromarray(img_)\n",
        "      draw = ImageDraw.Draw(img_)\n",
        "      draw.text((5,5), word_, font=font, fill=(256,256,256))\n",
        "      img_ = np.array(img_)\n",
        "      l, r, _, _ = self._find_pos(img_)\n",
        "      w_li_.append(r - l)\n",
        "    font_term = 5 - l\n",
        "    word_term = w_li_[2] - w_li_[0] - w_li_[0]\n",
        "    space_term = w_li_[1] - w_li_[0] - w_li_[0] + 2\n",
        "\n",
        "    color_1 = (self.ri(0,255), self.ri(0,255), self.ri(0,255))\n",
        "    color_2 = (self.ri(0,255), self.ri(0,255), self.ri(0,255))\n",
        "    while color_1 == color_2:\n",
        "      color_2 = (self.ri(0,255), self.ri(0,255), self.ri(0,255))\n",
        "\n",
        "    img_style = (color_1,color_2)\n",
        "\n",
        "    word_rotation = self.ri(-90, 90)\n",
        "\n",
        "    r_data = {\n",
        "        'length': length,\n",
        "        'font': font,\n",
        "        'font_name': r_font,\n",
        "        'font_term': font_term,\n",
        "        'word_term': word_term,\n",
        "        'space_term': space_term,\n",
        "        'letter_size': letter_size,\n",
        "        'word': word,\n",
        "        'word_rotation': word_rotation,\n",
        "        'back_img_size': back_img_size,\n",
        "        'img_style': img_style,\n",
        "        'rect_pos': []\n",
        "    }\n",
        "    return r_data\n",
        "\n",
        "  def _save(self, num, r_data):\n",
        "    with open(self.label_loc + str(num) + '.txt', mode='wt', encoding='utf-8') as f:\n",
        "      h, w, c = r_data['img'].shape\n",
        "      r_data['rect_pos'] = np.array(r_data['rect_pos'], dtype=np.int64)\n",
        "      for i, letter in enumerate(r_data['word']):\n",
        "        rect = r_data['rect_pos'][i]\n",
        "        x = round(((rect[1] - rect[0])/2 + rect[0])/w, 6)\n",
        "        y = round(((rect[3] - rect[2])/2 + rect[2])/h, 6)\n",
        "        height = round((rect[3] - rect[2])/h, 6)\n",
        "        width = round((rect[1] - rect[0])/w, 6)\n",
        "        split_letter = split_syllables(letter)\n",
        "        len_ = len(split_letter) \n",
        "        for pos_ in reversed(range(len_)):\n",
        "          if pos_ == 2:\n",
        "            if split_letter[pos_] in self.info['char_dic']:\n",
        "              index = self.info['char_dic'][split_letter[pos_]]\n",
        "            else:\n",
        "              try:\n",
        "                index = self.info['0'].index(split_letter[pos_])\n",
        "              except:\n",
        "                raise Exception(num, \"번쨰 데이터에서 charecter에 없는 데이터('\",s_thing,\"')가 발생했습니다. 추가해주세요.\")\n",
        "            f.write(\"{} {:.06f} {:.06f} {:.06f} {:.06f}\\n\".format(index, x, y+0.000001, width, height))\n",
        "\n",
        "          elif pos_ == 0:\n",
        "            try:\n",
        "              index = self.info['0'].index(split_letter[pos_])\n",
        "            except:\n",
        "              raise Exception(num, \"번쨰 데이터에서 charecter에 없는 데이터('\",s_thing,\"')가 발생했습니다. 추가해주세요.\")\n",
        "            f.write(\"{} {:.06f} {:.06f} {:.06f} {:.06f}\\n\".format(index, x-0.000001, y, width, height))\n",
        "          elif pos_ == 1:\n",
        "            try:\n",
        "              index = self.info['0'].index(split_letter[pos_])\n",
        "            except:\n",
        "              raise Exception(num, \"번쨰 데이터에서 charecter에 없는 데이터('\",s_thing,\"')가 발생했습니다. 추가해주세요.\")\n",
        "            f.write(\"{} {:.06f} {:.06f} {:.06f} {:.06f}\\n\".format(index, x, y, width+0.000001, height))\n",
        "\n",
        "        f.write(\"{} {:.06f} {:.06f} {:.06f} {:.06f}\\n\".format(160, x, y, width, height))\n",
        "    cv2.imwrite(self.img_loc + str(num)+'.jpg', r_data['img'])\n",
        "\n",
        "  def _error(self, error_code, data=None):\n",
        "    if error_code == 'InputError':\n",
        "      raise Exception(\"InputError\\n\\n가능한 버전이 이렇게 있습니다\\n1. 인덱스(list-int)와 data(list-str) 특정\\n2. data(list-str)만 특정 (index=None)\\n3. index(int)개수 만큼의 랜덤 데이터(data=None)\\n\\n위의 형식에 맞게 데이터를 넣어주세요\\n>> start(self, index, data = None, show_img=False)\")\n",
        "    \n",
        "    if error_code == 'CropError':\n",
        "      raise Exception('\\n\\nCropError.문자 위치 특정 작업을 실패했습니다. \\nlength:',data['length'],'\\nword:',data['word'],'\\n\\n다음 인덱스로 넘어갑니다.')\n",
        "\n",
        "  def _find_pos(self, img, r_data=None):\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    contours, _ = cv2.findContours(img_gray,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    contours_xy = np.array(contours)\n",
        "    x_value = []\n",
        "    y_value = []\n",
        "    for i in range(len(contours_xy)):\n",
        "        for j in range(len(contours_xy[i])):\n",
        "            x_value.append(contours_xy[i][j][0][0]) #네번째 괄호가 0일때 x의 값\n",
        "            y_value.append(contours_xy[i][j][0][1]) #네번째 괄호가 0일때 x의 값\n",
        "    try:\n",
        "      x_min = min(x_value)\n",
        "      x_max = max(x_value)\n",
        "      y_min = min(y_value)\n",
        "      y_max = max(y_value)\n",
        "    except ValueError:\n",
        "      raise Exception()\n",
        "\n",
        "    if r_data == None:\n",
        "      return x_min, x_max, y_min, y_max # left, right, up, down\n",
        "    else:\n",
        "      r_data['rect_pos'].append([x_min, x_max, y_min, y_max])\n",
        "\n",
        "\n",
        "\n",
        "  def _draw_rect(self, img, pt1, pt2, color = (255,255,255)):\n",
        "    cv2.rectangle(img, pt1, pt2, color, 1)\n",
        "    return img\n",
        "\n",
        "  def _draw_text(self, img, text, point, r_data):\n",
        "    img = Image.fromarray(img)\n",
        "    draw = ImageDraw.Draw(img)\n",
        "    draw.text(point, text, font=r_data['font'], fill=(256,256,256))\n",
        "    img = np.array(img)\n",
        "    return img\n",
        "\n",
        "  def _make_img(self, r_data):\n",
        "    img = np.zeros(r_data['back_img_size'], dtype=np.uint8)\n",
        "    start_y = int(r_data['back_img_size'][0]/2 - r_data['letter_size']/2)\n",
        "    start_x = r_data['letter_size']\n",
        "    r_data['rect_pos'] = []\n",
        "    term_ = 0\n",
        "    for letter in r_data['word']:\n",
        "      if letter == ' ':\n",
        "        img_ = np.zeros(r_data['back_img_size'], dtype=np.uint8)\n",
        "        img_ = self._draw_rect(img_, (start_x+term_, start_y), (start_x+term_+r_data['space_term'], start_y+r_data['letter_size']+2))\n",
        "        try:\n",
        "          left, right, up, down = self._find_pos(img_)\n",
        "        except:\n",
        "          self._error(\"CropError\", data=r_data)\n",
        "        term_ = int(term_ + right - r_data['font_term'] - left)\n",
        "        img_ = self._give_style(r_data, img_)\n",
        "        self._find_pos(img_, r_data=r_data)\n",
        "\n",
        "      else:\n",
        "        img_ = np.zeros(r_data['back_img_size'], dtype=np.uint8)\n",
        "        img_ = self._draw_text(img_, letter, (start_x+term_, start_y), r_data)\n",
        "        try:\n",
        "          left, right, up, down = self._find_pos(img_)\n",
        "        except:\n",
        "          self._error(\"CropError\", data=r_data)\n",
        "        if left == None:\n",
        "          raise Exception('현재 letter(', letter, ')가 표현이 되지 않습니다.\\n폰트:',r_data['font_name'],' \\n다음 인덱스로 넘어갑니다')\n",
        "        term_ = int(term_ + right - r_data['font_term'] + r_data['word_term'] - left)\n",
        "        img_ = self._give_style(r_data, img_)\n",
        "        self._find_pos(img_, r_data=r_data)\n",
        "        img = cv2.bitwise_or(img, img_)\n",
        "\n",
        "    r_data['word_pos'] = self._find_pos(img)\n",
        "    r_data['img'] = img\n",
        "  \n",
        "  def _crop_img(self, r_data, margin = 20):\n",
        "    left, right, up, down = r_data['word_pos']\n",
        "    if up - margin < 0 or left - margin < 0:\n",
        "      return\n",
        "    r_data['img'] = r_data['img'][up - margin : down + margin, left - margin: right + margin, :].copy()\n",
        "    r_data['rect_pos'] = np.array(r_data['rect_pos'], dtype=np.float64)\n",
        "    sum_ = np.array([-left + margin, -left + margin, -up + margin, -up + margin])\n",
        "    r_data['rect_pos'] += sum_\n",
        "\n",
        "  def _draw_pos(self, r_data):\n",
        "    img = r_data['img'].copy()\n",
        "    r_data['rect_pos'] = np.array(r_data['rect_pos'], dtype=np.int64)\n",
        "    for rect in r_data['rect_pos']:\n",
        "      img = self._draw_rect(img, (rect[0], rect[2]), (rect[1], rect[3]), color=(255,0,0))\n",
        "    print(r_data['word'])\n",
        "    return img\n",
        "  \n",
        "  def _resize(self, r_data, size = 200):\n",
        "    height, width, channel = r_data['img'].shape\n",
        "    r_data['rect_pos'] = np.array(r_data['rect_pos'], dtype=np.float64)\n",
        "    if height <= size:\n",
        "      if width <= size:\n",
        "        return\n",
        "    if height > width:\n",
        "      ratio_ = size / height\n",
        "      size_ = (int(ratio_*width),size)\n",
        "    else:\n",
        "      ratio_ = size / width\n",
        "      size_ = (size, int(ratio_*height))\n",
        "    r_data['img'] = cv2.resize(r_data['img'], size_)\n",
        "    r_data['rect_pos'] *= ratio_\n",
        "  \n",
        "  def _over_img(self, r_data):\n",
        "    height, width, channel = r_data['back_img_size']\n",
        "    back = np.full((height, width, channel), r_data['img_style'][0])\n",
        "    text = np.full((height, width, channel), r_data['img_style'][1])\n",
        "    text = (text / 250) * r_data['img']\n",
        "    r_data['img'] = cv2.add(back,text,dtype=cv2.CV_64F)\n",
        "\n",
        "    for _ in range(self.ri(0,(height*width)//20000)):\n",
        "      pt1 = (self.ri(0, height), self.ri(0, height))\n",
        "      pt2 = (self.ri(0, width), self.ri(0, width))\n",
        "      color = (self.ri(0,255), self.ri(0,255), self.ri(0,255))\n",
        "      r_data['img'] = cv2.line(r_data['img'], pt1, pt2, color, thickness=self.ri(1,2))\n",
        "    for _ in range(self.ri(0,(height*width)//2000)):\n",
        "      center = (self.ri(0, width), self.ri(0, height))\n",
        "      color = (self.ri(0,255), self.ri(0,255), self.ri(0,255))\n",
        "      r_data['img'] = cv2.circle(r_data['img'], center, self.ri(0, 5), color, thickness=self.ri(1,2))\n",
        "\n",
        "  def start(self, index, data = None, show=False):\n",
        "    if type(index)==int:\n",
        "        index = range(index)\n",
        "    elif type(index)==str:\n",
        "      self._error('InputError')\n",
        "        \n",
        "    elif type(index) == list or type(index) == range:\n",
        "      if type(index[0]) == str:\n",
        "        self._error('InputError')\n",
        "      elif data == None:\n",
        "        pass\n",
        "      else:\n",
        "        if len(index) != len(data):\n",
        "          raise Exception(\"데이터와 인덱스의 길이가 다릅니다.\")\n",
        "  \n",
        "    for i in tqdm(index):\n",
        "      try:\n",
        "        if data == None:\n",
        "          r_data = self._get_data(None)\n",
        "        else:\n",
        "          r_data = self._get_data(str(data[index.index(i)]))\n",
        "\n",
        "        self._make_img(r_data)\n",
        "        self._over_img(r_data)\n",
        "        self._crop_img(r_data)\n",
        "        self._resize(r_data)\n",
        "        self._save(i, r_data)\n",
        "\n",
        "        #cv2_imshow(self._draw_pos(r_data))\n",
        "\n",
        "      except Exception as e:\n",
        "        print('\\n', str(e))\n",
        "\n",
        "  def make_word(self, data, length):\n",
        "    data = np.array(data)\n",
        "    try:\n",
        "      kmeans = KMeans(n_clusters=length)\n",
        "      kmeans.fit(data[:,0:1])\n",
        "      pred = kmeans.predict(data[:,0:1])\n",
        "    except:\n",
        "      return False\n",
        "\n",
        "    min_ = min(pred)\n",
        "    max_ = max(pred)\n",
        "    word=[]\n",
        "\n",
        "    for i in range(min_, max_+1):\n",
        "      pos = [j for j in range(len(pred)) if pred[j]==i]\n",
        "      temp = []\n",
        "      for j in pos:\n",
        "        temp.append(list(data[j,:]))\n",
        "      word.append(temp)\n",
        "\n",
        "    ans = []\n",
        "    word.sort(key=lambda x:x[0])\n",
        "    for letter in word:\n",
        "      letter.sort(key=lambda x:x[1])\n",
        "      temp = [int(i[2]) for i in letter]\n",
        "      if len(temp) == 1:\n",
        "        temp = self.info['ans_cha'][temp[0]]\n",
        "      elif len(temp) == 2:\n",
        "        temp = [self.info['ans_cha'][i] for i in temp]\n",
        "        if temp[0] in 'ㅏㅐㅑㅒㅓㅔㅕㅖㅗㅘㅙㅚㅛㅜㅝㅞㅟㅠㅡㅢㅣ':\n",
        "          temp[0], temp[1] = temp[1], temp[0]\n",
        "      elif len(temp) == 3:\n",
        "        temp_ = []\n",
        "        for i in range(len(temp)):\n",
        "          if temp[i] < 133:\n",
        "            temp_.append(self.info['ans_cha'][temp[i]])\n",
        "          elif temp[i] < 144:\n",
        "            jong = self.info['ans_cha'][temp[i]]\n",
        "          else:\n",
        "            jong = self.info['char_dic'][temp[i]]\n",
        "          \n",
        "        if temp_[0] in 'ㅏㅐㅑㅒㅓㅔㅕㅖㅗㅘㅙㅚㅛㅜㅝㅞㅟㅠㅡㅢㅣ':\n",
        "          temp_[0], temp_[1] = temp_[1], temp_[0]\n",
        "        if jong:\n",
        "          temp_.append(jong)\n",
        "        temp = temp_\n",
        "      ans.append(join_jamos(\"\".join(temp)))\n",
        "      \n",
        "    return \"\".join(ans)\n",
        "    \n",
        "generater = hangle_img()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jE_XoOkfNyir"
      },
      "outputs": [],
      "source": [
        "# num_cores = multiprocessing.cpu_count()\n",
        "# index_list = range(30000)\n",
        "# splited_index = np.array_split(index_list, num_cores)\n",
        "\n",
        "# parmap.map(generater.start ,splited_index,pm_pbar=True,pm_processes=num_cores)\n",
        "# print('Done!!')\n",
        "\n",
        "# save_path = os.getcwd()+'/mk_img.zip'\n",
        "# %cd dataset\n",
        "# !zip '{save_path}' -r ./*\n",
        "# %cd ..\n",
        "\n",
        "save_path = os.getcwd()+'/mk_img.zip'\n",
        "to_ = os.getcwd()+'/dataset'\n",
        "!unzip -n '{save_path}' -d '{to_}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1wYvTeZS1zV"
      },
      "outputs": [],
      "source": [
        "img_list = glob(os.getcwd()+\"/dataset/images/*.jpg\")\n",
        "print(len(img_list))\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_img_list, val_img_list = train_test_split(img_list, test_size = 0.2, random_state=2000)\n",
        "print(len(train_img_list), len(val_img_list))\n",
        "\n",
        "with open(os.getcwd()+\"/dataset/train.txt\", \"w\") as f:\n",
        "  f.write('\\n'.join(train_img_list)+'\\n')\n",
        "with open(os.getcwd()+\"/dataset/val.txt\", \"w\") as f:\n",
        "  f.write('\\n'.join(val_img_list)+'\\n')\n",
        "\n",
        "with open(os.getcwd() + '/dataset/data.yaml', 'r') as f:\n",
        "  data = yaml.load(f)\n",
        "\n",
        "data['train'] = os.getcwd() + \"/dataset/train.txt\"\n",
        "data['val'] = os.getcwd() + \"/dataset/val.txt\"\n",
        "data['nc'] = 161\n",
        "data['names'] = ['space','giuk','Xgiuk','nien','diged','Xdiged','lier', 'miem', 'biep', 'Xbiep', 'siot', 'Xsiot', 'ieng', 'jied', 'Xjied', 'chied', 'kieck', 'tiet', 'piep', 'hied', 'AH', 'AEH-I', 'YAH', 'YAEH-I', 'EOH', 'AEH-O', 'YEOH', 'YAEH-O', 'OH', 'OH-AH' ,'OH-AEH-I', 'OH-EE', 'YOH', 'OO', 'OO-EOH', 'OO-AEH-O', 'OO-EE', 'YOO', 'EH', 'EH-EE' ,'EE', 'a' ,'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9','.', ',', '/', '?', \"'\",'\"', ';',':',']','[','}','{',')','(','<', '>', '+', '=', '-', '_', '*', '&', '^', '%', '$', '#', '@', '!', '~', '\\\\', '_gisi', '_niji', '_nihi', '_ligi', '_limi', '_libi', '_lisi', '_liti' ,'_lipi', '_lihi', '_bisi', '_giuk', '_Xgiuk', '_nien', '_diged', '_lier', '_miem', '_biep', '_siot', '_Xsiot', '_ieng', '_jied', '_chied', '_kieck', '_tiet', '_piep', '_hied', 'letter']                                    \n",
        "\n",
        "with open(os.getcwd() + '/dataset/data.yaml', 'w') as f:\n",
        "  yaml.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCkJwZca2BQr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWuWO9fYS8Mv"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "%cd /\n",
        "%cd /content/yolov5\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir /content/yolov5/runs/\n",
        "!nvidia-smi\n",
        "\n",
        "# %cp /content/drive/MyDrive/KB_OCR/model5_4/last.pt /content/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUfA3V5XnaFf"
      },
      "outputs": [],
      "source": [
        "%cp /content/drive/MyDrive/KB_OCR/model5_4/* /content/yolov5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRo_SsZHcS1D"
      },
      "outputs": [],
      "source": [
        "!python train.py --img 224 --batch 100 --epoch 1000 --data /content/dataset/data.yaml --cfg ./models/yolov5x.yaml --weights last.pt --name OCR_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPrhvQ39QbEu"
      },
      "outputs": [],
      "source": [
        "33"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fE2rRSZ121R8"
      },
      "outputs": [],
      "source": [
        "%cp /content/yolov5/runs/train/OCR_result2/weights/* /content/drive/MyDrive/KB_OCR/model5_4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0AXoiWPVuqs"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "val_img_path= os.getcwd() + '/dataset/images/'\n",
        "weights_path = os.getcwd() + '/yolov5/best.pt'\n",
        "%cd yolov5/\n",
        "!python detect.py --weights '{weights_path}' --img 224 --conf 0.3 --source \"{val_img_path}\" --save-txt --line-thicknes 1\n",
        "%cd ..\n",
        "\n",
        "label_list = glob(os.getcwd() + '/yolov5/runs/detect/exp2/labels/*.txt')\n",
        "\n",
        "for lable_dir in label_list:\n",
        "  with open(lable_dir, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "  data, length, num = [], 0, lable_dir.split('/')[-1]\n",
        "  for line in lines:\n",
        "    l_list =line.split(\" \")\n",
        "    if int(l_list[0]) == 160:\n",
        "      length += 1\n",
        "      continue\n",
        "    data.append([float(l_list[1]), float(l_list[2]), int(l_list[0])])\n",
        "  ans = generater.make_word(data, length)\n",
        "  print(num, ' : ',ans)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = glob(os.getcwd() + '/yolov5/runs/detect/exp2/labels/*.txt')\n",
        "\n",
        "for lable_dir in label_list:\n",
        "  with open(lable_dir, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "  data, length, num = [], 0, lable_dir.split('/')[-1]\n",
        "  for line in lines:\n",
        "    l_list =line.split(\" \")\n",
        "    if int(l_list[0]) == 160:\n",
        "      length += 1\n",
        "      continue\n",
        "    data.append([float(l_list[1]), float(l_list[2]), int(l_list[0])])\n",
        "  ans = generater.make_word(data, length)\n",
        "  print(num, ' : ',ans)"
      ],
      "metadata": {
        "id": "4fL2c2TLvgZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(\"/content/dataset/images/\", cv2.IMREAD_COLOR)"
      ],
      "metadata": {
        "id": "4asi2s2ExV7A"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "model5_4.ipynb",
      "provenance": [],
      "mount_file_id": "1pqOy3wxaeSxTHS7zXp7etADLRwvte9so",
      "authorship_tag": "ABX9TyObXj0P2DcaiPUt47mQwI34",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}